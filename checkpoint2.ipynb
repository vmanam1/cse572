{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "967fcbd1",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb8a35a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (64374, 12)\n",
      "\n",
      "Data Types and Non-Null Counts:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64374 entries, 0 to 64373\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   CustomerID         64374 non-null  int64 \n",
      " 1   Age                64374 non-null  int64 \n",
      " 2   Gender             64374 non-null  object\n",
      " 3   Tenure             64374 non-null  int64 \n",
      " 4   Usage Frequency    64374 non-null  int64 \n",
      " 5   Support Calls      64374 non-null  int64 \n",
      " 6   Payment Delay      64374 non-null  int64 \n",
      " 7   Subscription Type  64374 non-null  object\n",
      " 8   Contract Length    64374 non-null  object\n",
      " 9   Total Spend        64374 non-null  int64 \n",
      " 10  Last Interaction   64374 non-null  int64 \n",
      " 11  Churn              64374 non-null  int64 \n",
      "dtypes: int64(9), object(3)\n",
      "memory usage: 5.9+ MB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "         CustomerID           Age        Tenure  Usage Frequency  \\\n",
      "count  64374.000000  64374.000000  64374.000000     64374.000000   \n",
      "mean   32187.500000     41.970982     31.994827        15.080234   \n",
      "std    18583.317451     13.924911     17.098234         8.816470   \n",
      "min        1.000000     18.000000      1.000000         1.000000   \n",
      "25%    16094.250000     30.000000     18.000000         7.000000   \n",
      "50%    32187.500000     42.000000     33.000000        15.000000   \n",
      "75%    48280.750000     54.000000     47.000000        23.000000   \n",
      "max    64374.000000     65.000000     60.000000        30.000000   \n",
      "\n",
      "       Support Calls  Payment Delay   Total Spend  Last Interaction  \\\n",
      "count   64374.000000   64374.000000  64374.000000      64374.000000   \n",
      "mean        5.400690      17.133952    541.023379         15.498850   \n",
      "std         3.114005       8.852211    260.874809          8.638436   \n",
      "min         0.000000       0.000000    100.000000          1.000000   \n",
      "25%         3.000000      10.000000    313.000000          8.000000   \n",
      "50%         6.000000      19.000000    534.000000         15.000000   \n",
      "75%         8.000000      25.000000    768.000000         23.000000   \n",
      "max        10.000000      30.000000   1000.000000         30.000000   \n",
      "\n",
      "              Churn  \n",
      "count  64374.000000  \n",
      "mean       0.473685  \n",
      "std        0.499311  \n",
      "min        0.000000  \n",
      "25%        0.000000  \n",
      "50%        0.000000  \n",
      "75%        1.000000  \n",
      "max        1.000000  \n",
      "\n",
      "First 5 Rows:\n",
      "   CustomerID  Age  Gender  Tenure  Usage Frequency  Support Calls  \\\n",
      "0           1   22  Female      25               14              4   \n",
      "1           2   41  Female      28               28              7   \n",
      "2           3   47    Male      27               10              2   \n",
      "3           4   35    Male       9               12              5   \n",
      "4           5   53  Female      58               24              9   \n",
      "\n",
      "   Payment Delay Subscription Type Contract Length  Total Spend  \\\n",
      "0             27             Basic         Monthly          598   \n",
      "1             13          Standard         Monthly          584   \n",
      "2             29           Premium          Annual          757   \n",
      "3             17           Premium       Quarterly          232   \n",
      "4              2          Standard          Annual          533   \n",
      "\n",
      "   Last Interaction  Churn  \n",
      "0                 9      1  \n",
      "1                20      0  \n",
      "2                21      0  \n",
      "3                18      0  \n",
      "4                18      0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"customer_churn_dataset.csv\")\n",
    "\n",
    "# Basic info\n",
    "print(\"Shape of dataset:\", df.shape)\n",
    "print(\"\\nData Types and Non-Null Counts:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nFirst 5 Rows:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647c39cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values Per Column:\n",
      "CustomerID           0\n",
      "Age                  0\n",
      "Gender               0\n",
      "Tenure               0\n",
      "Usage Frequency      0\n",
      "Support Calls        0\n",
      "Payment Delay        0\n",
      "Subscription Type    0\n",
      "Contract Length      0\n",
      "Total Spend          0\n",
      "Last Interaction     0\n",
      "Churn                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Missing values check\n",
    "print(\"\\nMissing Values Per Column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d11d0b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Shape: (64374, 11)\n"
     ]
    }
   ],
   "source": [
    "# Drop irrelevant column\n",
    "df = df.drop(columns=['CustomerID'])\n",
    "\n",
    "# Confirm shape after dropping\n",
    "print(\"New Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13f6993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Age        Tenure  Usage Frequency  Support Calls  \\\n",
      "count  64374.000000  64374.000000     64374.000000   64374.000000   \n",
      "mean      41.970982     31.994827        15.080234       5.400690   \n",
      "std       13.924911     17.098234         8.816470       3.114005   \n",
      "min       18.000000      1.000000         1.000000       0.000000   \n",
      "25%       30.000000     18.000000         7.000000       3.000000   \n",
      "50%       42.000000     33.000000        15.000000       6.000000   \n",
      "75%       54.000000     47.000000        23.000000       8.000000   \n",
      "max       65.000000     60.000000        30.000000      10.000000   \n",
      "\n",
      "       Payment Delay   Total Spend  Last Interaction         Churn  \n",
      "count   64374.000000  64374.000000      64374.000000  64374.000000  \n",
      "mean       17.133952    541.023379         15.498850      0.473685  \n",
      "std         8.852211    260.874809          8.638436      0.499311  \n",
      "min         0.000000    100.000000          1.000000      0.000000  \n",
      "25%        10.000000    313.000000          8.000000      0.000000  \n",
      "50%        19.000000    534.000000         15.000000      0.000000  \n",
      "75%        25.000000    768.000000         23.000000      1.000000  \n",
      "max        30.000000   1000.000000         30.000000      1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Summary stats for numerical columns\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25cfa63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types after encoding:\n",
      "Age                           int64\n",
      "Gender                        int64\n",
      "Tenure                        int64\n",
      "Usage Frequency               int64\n",
      "Support Calls                 int64\n",
      "Payment Delay                 int64\n",
      "Contract Length               int64\n",
      "Total Spend                   int64\n",
      "Last Interaction              int64\n",
      "Churn                         int64\n",
      "Subscription Type_Premium      bool\n",
      "Subscription Type_Standard     bool\n",
      "dtype: object\n",
      "\n",
      "Unique values per categorical column:\n",
      "Gender: [0 1]\n",
      "Contract Length: [ 1 12  3]\n",
      "Subscription Type columns: ['Subscription Type_Premium', 'Subscription Type_Standard']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Encode Gender\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# 2. One-hot encode Subscription Type\n",
    "df = pd.get_dummies(df, columns=['Subscription Type'], drop_first=True)  \n",
    "# drop_first=True avoids dummy trap (creates k-1 columns)\n",
    "\n",
    "# 3. Map Contract Length to numeric months\n",
    "contract_map = {'Monthly': 1, 'Quarterly': 3, 'Annual': 12}\n",
    "df['Contract Length'] = df['Contract Length'].map(contract_map)\n",
    "\n",
    "# Verify changes\n",
    "print(\"\\nData types after encoding:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nUnique values per categorical column:\")\n",
    "print(\"Gender:\", df['Gender'].unique())\n",
    "print(\"Contract Length:\", df['Contract Length'].unique())\n",
    "print(\"Subscription Type columns:\", [col for col in df.columns if \"Subscription Type\" in col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59fe91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age  Gender  Tenure  Usage Frequency  Support Calls  Payment Delay  \\\n",
      "0    22       0      25               14              4             27   \n",
      "1    41       0      28               28              7             13   \n",
      "2    47       1      27               10              2             29   \n",
      "3    35       1       9               12              5             17   \n",
      "4    53       0      58               24              9              2   \n",
      "5    30       1      41               14             10             10   \n",
      "6    47       0      37               15              9             28   \n",
      "7    54       0      36               11              0             18   \n",
      "8    36       1      20                5             10              8   \n",
      "9    65       1       8                4              2             23   \n",
      "10   46       0      42               27              9             21   \n",
      "11   56       1      13               23              5             14   \n",
      "12   31       1       2                7              0             25   \n",
      "13   42       1      46               27              5              8   \n",
      "14   59       1      21               17              2             14   \n",
      "15   35       0       1                3              7              3   \n",
      "16   29       1      54                3              6              2   \n",
      "17   45       1       9               30              4             25   \n",
      "18   65       0      40                2              1              6   \n",
      "19   62       1      39               19              2             15   \n",
      "20   48       1      28                7              1             21   \n",
      "21   36       0      58                4              0              1   \n",
      "22   55       1      50               28              0             17   \n",
      "23   36       0      54               20              4              1   \n",
      "24   64       1      59                7              5              9   \n",
      "25   65       0      58                7              3             30   \n",
      "26   53       0      58               18              8              4   \n",
      "27   41       0      60                7              7              0   \n",
      "28   25       0      41               11              5             11   \n",
      "29   44       0      44                7              8             16   \n",
      "\n",
      "    Contract Length  Total Spend  Last Interaction  Churn  \\\n",
      "0                 1          598                 9      1   \n",
      "1                 1          584                20      0   \n",
      "2                12          757                21      0   \n",
      "3                 3          232                18      0   \n",
      "4                12          533                18      0   \n",
      "5                 1          500                29      0   \n",
      "6                 3          574                14      1   \n",
      "7                 1          323                16      0   \n",
      "8                 1          687                 8      0   \n",
      "9                12          995                10      0   \n",
      "10               12          526                 3      1   \n",
      "11                3          187                 1      0   \n",
      "12                3          758                24      0   \n",
      "13                3          438                30      0   \n",
      "14                3          663                15      0   \n",
      "15                1          677                25      1   \n",
      "16                1          636                22      0   \n",
      "17               12          127                18      0   \n",
      "18               12          396                21      0   \n",
      "19                3          202                24      0   \n",
      "20                1          925                13      0   \n",
      "21                3          463                26      0   \n",
      "22                3          449                 3      0   \n",
      "23                1          373                25      0   \n",
      "24               12          460                12      0   \n",
      "25               12          166                 1      1   \n",
      "26                3          615                 4      0   \n",
      "27               12          696                20      0   \n",
      "28               12          678                30      0   \n",
      "29                3          792                27      1   \n",
      "\n",
      "    Subscription Type_Premium  Subscription Type_Standard  \n",
      "0                       False                       False  \n",
      "1                       False                        True  \n",
      "2                        True                       False  \n",
      "3                        True                       False  \n",
      "4                       False                        True  \n",
      "5                        True                       False  \n",
      "6                       False                       False  \n",
      "7                       False                        True  \n",
      "8                       False                       False  \n",
      "9                       False                       False  \n",
      "10                      False                        True  \n",
      "11                      False                       False  \n",
      "12                       True                       False  \n",
      "13                       True                       False  \n",
      "14                       True                       False  \n",
      "15                      False                       False  \n",
      "16                      False                       False  \n",
      "17                      False                       False  \n",
      "18                       True                       False  \n",
      "19                       True                       False  \n",
      "20                       True                       False  \n",
      "21                       True                       False  \n",
      "22                      False                        True  \n",
      "23                      False                       False  \n",
      "24                      False                       False  \n",
      "25                       True                       False  \n",
      "26                      False                       False  \n",
      "27                       True                       False  \n",
      "28                       True                       False  \n",
      "29                      False                       False  \n"
     ]
    }
   ],
   "source": [
    "# Display 15 sample rows after encoding\n",
    "print(df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49350f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard    21502\n",
      "Premium     21421\n",
      "Basic       21451\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count how many customers are Standard, Premium, and Basic\n",
    "subscription_counts = pd.Series(dtype=int)\n",
    "\n",
    "subscription_counts['Standard'] = df['Subscription Type_Standard'].sum()\n",
    "subscription_counts['Premium'] = df['Subscription Type_Premium'].sum()\n",
    "subscription_counts['Basic'] = len(df) - (subscription_counts['Standard'] + subscription_counts['Premium'])\n",
    "\n",
    "print(subscription_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9998f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Age    Tenure  Usage Frequency  Support Calls  Payment Delay  \\\n",
      "0 -1.434202 -0.409100        -0.122526      -0.449807       1.114538   \n",
      "1 -0.069730 -0.233642         1.465424       0.513590      -0.467000   \n",
      "2  0.361155 -0.292128        -0.576225      -1.092072       1.340472   \n",
      "3 -0.500616 -1.344876        -0.349375      -0.128674      -0.015132   \n",
      "4  0.792041  1.520939         1.011724       1.155855      -1.709637   \n",
      "\n",
      "   Last Interaction  Total Spend  \n",
      "0         -0.752324     0.218408  \n",
      "1          0.521065     0.164742  \n",
      "2          0.636827     0.827900  \n",
      "3          0.289540    -1.184575  \n",
      "4          0.289540    -0.030756  \n",
      "\n",
      "Scaled column means (should be close to 0):\n",
      " Age                -1.801357e-16\n",
      "Tenure             -9.183390e-17\n",
      "Usage Frequency     5.651317e-17\n",
      "Support Calls      -1.483471e-16\n",
      "Payment Delay      -1.554112e-16\n",
      "Last Interaction    2.560753e-17\n",
      "Total Spend        -4.944902e-17\n",
      "dtype: float64\n",
      "\n",
      "Scaled column std (should be close to 1):\n",
      " Age                 1.000008\n",
      "Tenure              1.000008\n",
      "Usage Frequency     1.000008\n",
      "Support Calls       1.000008\n",
      "Payment Delay       1.000008\n",
      "Last Interaction    1.000008\n",
      "Total Spend         1.000008\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns to scale\n",
    "scale_cols = ['Age', 'Tenure', 'Usage Frequency', 'Support Calls',\n",
    "              'Payment Delay', 'Last Interaction', 'Total Spend']\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
    "\n",
    "# Verify scaling\n",
    "print(df[scale_cols].head())\n",
    "print(\"\\nScaled column means (should be close to 0):\\n\", df[scale_cols].mean())\n",
    "print(\"\\nScaled column std (should be close to 1):\\n\", df[scale_cols].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e40c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Contract Length  is_monthly  SupportCalls_per_Tenure  \\\n",
      "0                1           1                 1.099504   \n",
      "1                1           1                -2.198198   \n",
      "2               12           0                 3.738338   \n",
      "3                3           0                 0.095678   \n",
      "4               12           0                 0.759961   \n",
      "5                1           1                 2.804353   \n",
      "6                3           0                 3.948500   \n",
      "7                1           1                -7.403890   \n",
      "8                1           1                -2.105381   \n",
      "9               12           0                 0.778182   \n",
      "\n",
      "   DelayedPayments_percent  \n",
      "0                -2.724368  \n",
      "1                 1.998789  \n",
      "2                -4.588652  \n",
      "3                 0.011252  \n",
      "4                -1.124067  \n",
      "5                -1.530163  \n",
      "6                 4.193262  \n",
      "7                 0.417658  \n",
      "8                 1.470836  \n",
      "9                -0.472202  \n"
     ]
    }
   ],
   "source": [
    "# 1. is_monthly feature\n",
    "df['is_monthly'] = (df['Contract Length'] == 1).astype(int)\n",
    "\n",
    "# 2. Support Calls per Tenure (avoid division by zero using where)\n",
    "df['SupportCalls_per_Tenure'] = df['Support Calls'] / df['Tenure'].where(df['Tenure'] != 0, 1)\n",
    "\n",
    "# 3. Delayed Payments percentage\n",
    "df['DelayedPayments_percent'] = df['Payment Delay'] / df['Tenure'].where(df['Tenure'] != 0, 1)\n",
    "\n",
    "# Verify new features\n",
    "print(df[['Contract Length','is_monthly','SupportCalls_per_Tenure','DelayedPayments_percent']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cfb221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                           float64\n",
      "Gender                          int64\n",
      "Tenure                        float64\n",
      "Usage Frequency               float64\n",
      "Support Calls                 float64\n",
      "Payment Delay                 float64\n",
      "Contract Length                 int64\n",
      "Total Spend                   float64\n",
      "Last Interaction              float64\n",
      "Churn                           int64\n",
      "Subscription Type_Premium        bool\n",
      "Subscription Type_Standard       bool\n",
      "is_monthly                      int32\n",
      "SupportCalls_per_Tenure       float64\n",
      "DelayedPayments_percent       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values check:\n",
      " Age                           0\n",
      "Gender                        0\n",
      "Tenure                        0\n",
      "Usage Frequency               0\n",
      "Support Calls                 0\n",
      "Payment Delay                 0\n",
      "Contract Length               0\n",
      "Total Spend                   0\n",
      "Last Interaction              0\n",
      "Churn                         0\n",
      "Subscription Type_Premium     0\n",
      "Subscription Type_Standard    0\n",
      "is_monthly                    0\n",
      "SupportCalls_per_Tenure       0\n",
      "DelayedPayments_percent       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check missing values\n",
    "print(\"\\nMissing values check:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67132ad3",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "907f33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d795ed58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (51499, 14)\n",
      "Testing set shape: (12875, 14)\n",
      "\n",
      "Churn distribution in training set:\n",
      "Churn\n",
      "0    0.526321\n",
      "1    0.473679\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Churn distribution in test set:\n",
      "Churn\n",
      "0    0.526291\n",
      "1    0.473709\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop(columns=['Churn'])\n",
    "y = df['Churn']\n",
    "\n",
    "# Split into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Verify the split\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Testing set shape:\", X_test.shape)\n",
    "print(\"\\nChurn distribution in training set:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nChurn distribution in test set:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27ed49f",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c3d781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest Results ===\n",
      "Accuracy: 0.9973\n",
      "Precision: 0.9988\n",
      "Recall: 0.9954\n",
      "F1 Score: 0.9971\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6769    7]\n",
      " [  28 6071]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6776\n",
      "           1       1.00      1.00      1.00      6099\n",
      "\n",
      "    accuracy                           1.00     12875\n",
      "   macro avg       1.00      1.00      1.00     12875\n",
      "weighted avg       1.00      1.00      1.00     12875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"=== Random Forest Results ===\")\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "print(f\"F1 Score: {f1_rf:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f770f2c3",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9366376c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBoost Results ===\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6776    0]\n",
      " [   0 6099]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6776\n",
      "           1       1.00      1.00      1.00      6099\n",
      "\n",
      "    accuracy                           1.00     12875\n",
      "   macro avg       1.00      1.00      1.00     12875\n",
      "weighted avg       1.00      1.00      1.00     12875\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [16:00:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"=== XGBoost Results ===\")\n",
    "print(f\"Accuracy: {accuracy_xgb:.4f}\")\n",
    "print(f\"Precision: {precision_xgb:.4f}\")\n",
    "print(f\"Recall: {recall_xgb:.4f}\")\n",
    "print(f\"F1 Score: {f1_xgb:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8688c418",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a978f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# svm_linear = SVC(probability=True, random_state=42)\n",
    "# svm_linear.fit(X_train, y_train)\n",
    "# y_pred_svm_linear = svm_linear.predict(X_test)\n",
    "\n",
    "# print(\"=== Linear SVM Results ===\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm_linear):.4f}\")\n",
    "# print(f\"Precision: {precision_score(y_test, y_pred_svm_linear):.4f}\")\n",
    "# print(f\"Recall: {recall_score(y_test, y_pred_svm_linear):.4f}\")\n",
    "# print(f\"F1 Score: {f1_score(y_test, y_pred_svm_linear):.4f}\")\n",
    "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm_linear))\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm_linear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21352316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# # Use a smaller sample for faster RBF training\n",
    "# X_train_small = X_train.sample(10000, random_state=42)\n",
    "# y_train_small = y_train.sample(10000, random_state=42)\n",
    "\n",
    "# # Initialize and train RBF SVM\n",
    "# svm_rbf = SVC(kernel='rbf', C=1, gamma='scale', probability=True, random_state=42)\n",
    "# svm_rbf.fit(X_train_small, y_train_small)\n",
    "\n",
    "# # Predict\n",
    "# y_pred_svm_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# # Evaluate\n",
    "# print(\"=== RBF SVM Results ===\")\n",
    "# print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm_rbf):.4f}\")\n",
    "# print(f\"Precision: {precision_score(y_test, y_pred_svm_rbf):.4f}\")\n",
    "# print(f\"Recall: {recall_score(y_test, y_pred_svm_rbf):.4f}\")\n",
    "# print(f\"F1 Score: {f1_score(y_test, y_pred_svm_rbf):.4f}\")\n",
    "\n",
    "# print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_svm_rbf))\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm_rbf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc1a487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from lightgbm) (1.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5bdf301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 24394, number of negative: 27105\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 992\n",
      "[LightGBM] [Info] Number of data points in the train set: 51499, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.473679 -> initscore=-0.105381\n",
      "[LightGBM] [Info] Start training from score -0.105381\n",
      "=== LightGBM Results ===\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6776    0]\n",
      " [   0 6099]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6776\n",
      "           1       1.00      1.00      1.00      6099\n",
      "\n",
      "    accuracy                           1.00     12875\n",
      "   macro avg       1.00      1.00      1.00     12875\n",
      "weighted avg       1.00      1.00      1.00     12875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize LightGBM model\n",
    "lgb_model = LGBMClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train LightGBM\n",
    "print(\"Training LightGBM...\")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_lgb = accuracy_score(y_test, y_pred_lgb)\n",
    "precision_lgb = precision_score(y_test, y_pred_lgb)\n",
    "recall_lgb = recall_score(y_test, y_pred_lgb)\n",
    "f1_lgb = f1_score(y_test, y_pred_lgb)\n",
    "\n",
    "print(\"=== LightGBM Results ===\")\n",
    "print(f\"Accuracy: {accuracy_lgb:.4f}\")\n",
    "print(f\"Precision: {precision_lgb:.4f}\")\n",
    "print(f\"Recall: {recall_lgb:.4f}\")\n",
    "print(f\"F1 Score: {f1_lgb:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097097a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.2.8-cp310-cp310-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (3.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.16.0 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (1.15.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from pandas>=0.24->catboost) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Downloading catboost-1.2.8-cp310-cp310-win_amd64.whl (102.5 MB)\n",
      "   ---------------------------------------- 0.0/102.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/102.5 MB 8.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 2.6/102.5 MB 7.9 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 4.5/102.5 MB 7.5 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 6.3/102.5 MB 7.9 MB/s eta 0:00:13\n",
      "   --- ------------------------------------ 8.9/102.5 MB 8.9 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 11.0/102.5 MB 9.3 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 13.4/102.5 MB 9.3 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 15.5/102.5 MB 9.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 17.3/102.5 MB 9.3 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 18.9/102.5 MB 9.1 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 20.4/102.5 MB 8.9 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 22.0/102.5 MB 8.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 23.9/102.5 MB 8.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 26.0/102.5 MB 8.9 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 28.0/102.5 MB 9.0 MB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 30.4/102.5 MB 9.1 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 32.8/102.5 MB 9.2 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 34.9/102.5 MB 9.2 MB/s eta 0:00:08\n",
      "   -------------- ------------------------- 37.5/102.5 MB 9.4 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 39.8/102.5 MB 9.5 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 42.5/102.5 MB 9.5 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 44.0/102.5 MB 9.6 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 46.7/102.5 MB 9.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 47.7/102.5 MB 9.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 48.2/102.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 48.2/102.5 MB 9.4 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 49.0/102.5 MB 8.6 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 51.1/102.5 MB 8.7 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 53.5/102.5 MB 8.7 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 55.6/102.5 MB 8.8 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 57.4/102.5 MB 8.8 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 59.8/102.5 MB 8.9 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 62.7/102.5 MB 9.0 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 65.0/102.5 MB 9.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 66.3/102.5 MB 9.0 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 68.4/102.5 MB 9.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 71.3/102.5 MB 9.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 73.7/102.5 MB 9.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 76.5/102.5 MB 9.3 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 79.2/102.5 MB 9.4 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 81.8/102.5 MB 9.5 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 83.6/102.5 MB 9.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 84.9/102.5 MB 9.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 87.0/102.5 MB 9.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 88.1/102.5 MB 9.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 90.2/102.5 MB 9.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 92.5/102.5 MB 9.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 94.4/102.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 95.2/102.5 MB 9.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.0/102.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  100.7/102.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.0/102.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  102.2/102.5 MB 9.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 102.5/102.5 MB 9.2 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.8 graphviz-0.21\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e7738c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CatBoost...\n",
      "0:\tlearn: 0.9480079\ttotal: 129ms\tremaining: 38.6s\n",
      "50:\tlearn: 0.9998360\ttotal: 705ms\tremaining: 3.44s\n",
      "100:\tlearn: 0.9999795\ttotal: 1.26s\tremaining: 2.48s\n",
      "150:\tlearn: 0.9999795\ttotal: 1.78s\tremaining: 1.75s\n",
      "200:\tlearn: 1.0000000\ttotal: 2.3s\tremaining: 1.13s\n",
      "250:\tlearn: 1.0000000\ttotal: 2.79s\tremaining: 545ms\n",
      "299:\tlearn: 1.0000000\ttotal: 3.17s\tremaining: 0us\n",
      "\n",
      "=== CatBoost Results ===\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6776    0]\n",
      " [   0 6099]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6776\n",
      "           1       1.00      1.00      1.00      6099\n",
      "\n",
      "    accuracy                           1.00     12875\n",
      "   macro avg       1.00      1.00      1.00     12875\n",
      "weighted avg       1.00      1.00      1.00     12875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize CatBoost model\n",
    "cat_model = CatBoostClassifier(\n",
    "    iterations=300,\n",
    "    learning_rate=0.05,\n",
    "    depth=8,\n",
    "    eval_metric='F1',\n",
    "    random_seed=42,\n",
    "    verbose=50\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "print(\"Training CatBoost...\")\n",
    "cat_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_cat = cat_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy_cat = accuracy_score(y_test, y_pred_cat)\n",
    "precision_cat = precision_score(y_test, y_pred_cat)\n",
    "recall_cat = recall_score(y_test, y_pred_cat)\n",
    "f1_cat = f1_score(y_test, y_pred_cat)\n",
    "\n",
    "print(\"\\n=== CatBoost Results ===\")\n",
    "print(f\"Accuracy: {accuracy_cat:.4f}\")\n",
    "print(f\"Precision: {precision_cat:.4f}\")\n",
    "print(f\"Recall: {recall_cat:.4f}\")\n",
    "print(f\"F1 Score: {f1_cat:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_cat))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c0460e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP Neural Network...\n",
      "\n",
      "=== MLP (Neural Network) Results ===\n",
      "Accuracy: 0.9904\n",
      "Precision: 0.9882\n",
      "Recall: 0.9916\n",
      "F1 Score: 0.9899\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6704   72]\n",
      " [  51 6048]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      6776\n",
      "           1       0.99      0.99      0.99      6099\n",
      "\n",
      "    accuracy                           0.99     12875\n",
      "   macro avg       0.99      0.99      0.99     12875\n",
      "weighted avg       0.99      0.99      0.99     12875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize MLP model\n",
    "mlp_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # 3 hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=300,\n",
    "    random_state=42,\n",
    "    learning_rate_init=0.001\n",
    ")\n",
    "\n",
    "# Train the MLP\n",
    "print(\"Training MLP Neural Network...\")\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
    "\n",
    "print(\"\\n=== MLP (Neural Network) Results ===\")\n",
    "print(f\"Accuracy: {accuracy_mlp:.4f}\")\n",
    "print(f\"Precision: {precision_mlp:.4f}\")\n",
    "print(f\"Recall: {recall_mlp:.4f}\")\n",
    "print(f\"F1 Score: {f1_mlp:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c3831",
   "metadata": {},
   "source": [
    "## Another Dataset (as suggested by TA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d0010c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1495, number of negative: 4130\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 642\n",
      "[LightGBM] [Info] Number of data points in the train set: 5625, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.265778 -> initscore=-1.016151\n",
      "[LightGBM] [Info] Start training from score -1.016151\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL PERFORMANCE COMPARISON ===\n",
      "           Model  Accuracy  Precision    Recall  F1 Score\n",
      "1       LightGBM  0.783937   0.608696  0.524064  0.563218\n",
      "2       CatBoost  0.788202   0.625000  0.508021  0.560472\n",
      "0  Random Forest  0.785359   0.621622  0.491979  0.549254\n",
      "3            MLP  0.744136   0.519126  0.508021  0.513514\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# TELCO CUSTOMER CHURN  END-TO-END PIPELINE\n",
    "# Models: Random Forest, LightGBM, CatBoost, MLP\n",
    "# ==============================================\n",
    "\n",
    "#  Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#  Load Data\n",
    "df = pd.read_csv(\"telco_customer_churn.csv\")\n",
    "\n",
    "#  Step 1: Data Cleaning\n",
    "df['TotalCharges'] = df['TotalCharges'].replace(' ', np.nan)  # Replace blank strings with NaN\n",
    "df['TotalCharges'] = df['TotalCharges'].astype(float)\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "\n",
    "# Drop customerID as its not useful\n",
    "df.drop('customerID', axis=1, inplace=True)\n",
    "\n",
    "#  Step 2: Encode Target\n",
    "df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "#  Step 3: Encode Categorical Features\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "#  Step 4: Split Features and Target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "#  Step 5: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "#  Step 6: Scale Numeric Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#  Step 7: Train Models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=8, random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=200, learning_rate=0.05, depth=8, verbose=0, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation='relu', solver='adam',\n",
    "                         max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "#  Step 8: Evaluate Each Model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append([name, acc, prec, rec, f1])\n",
    "\n",
    "#  Step 9: Results Table\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "print(\"=== MODEL PERFORMANCE COMPARISON ===\")\n",
    "print(results_df.sort_values(by=\"F1 Score\", ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f37c01",
   "metadata": {},
   "source": [
    "# Another Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78340e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1630, number of negative: 6370\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 862\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203750 -> initscore=-1.363019\n",
      "[LightGBM] [Info] Start training from score -1.363019\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vmana\\anaconda3\\envs\\dm\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL PERFORMANCE COMPARISON (BANK CHURN) ===\n",
      "           Model  Accuracy  Precision    Recall  F1 Score\n",
      "2       CatBoost    0.8695   0.792000  0.486486  0.602740\n",
      "1       LightGBM    0.8630   0.750943  0.488943  0.592262\n",
      "0  Random Forest    0.8640   0.813953  0.429975  0.562701\n",
      "3            MLP    0.8175   0.552239  0.545455  0.548826\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# BANK CUSTOMER CHURN PIPELINE\n",
    "# Models: RF, LightGBM, CatBoost, MLP\n",
    "# ==============================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"bank_customer_churn.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_cols = ['Geography', 'Gender']\n",
    "for col in label_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Define X and y\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=200, learning_rate=0.05, max_depth=8, random_state=42),\n",
    "    \"CatBoost\": CatBoostClassifier(iterations=200, learning_rate=0.05, depth=8, verbose=0, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(128, 64, 32), activation='relu', solver='adam',\n",
    "                         max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    results.append([name, acc, prec, rec, f1])\n",
    "\n",
    "# Results summary\n",
    "results_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"])\n",
    "print(\"=== MODEL PERFORMANCE COMPARISON (BANK CHURN) ===\")\n",
    "print(results_df.sort_values(by=\"F1 Score\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
